#!/usr/bin/env ruby
require_relative '../lib/common/common.rb'
require_relative '../lib/indexer/indexer.rb'

# TODO: Eventuell wäre es auch interessant BigQueue um eine Bestätigungsfunktion zu erweitern, bzw. eine andere Warteschlange mit solcher Funktionalität
#       zu implementieren. So wäre es sichergestellt, dass einzelne Einträge am Ende nicht ohne Indexeinträge bleiben.
# TODO: Den Code übersichtlicher machen.

module Indexer
  class Main
    def initialize
      @logger = Common::Logger.new({labels: {tasks: "Aufgaben", tasks_per_second: "Aufgaben/s"}})
      @logger.add_output($stdout, Common::Logger::INFO)
      @progress = @logger.progress_logger(Common::OrderedHash.new([[:tasks, 0]]))
      @progress[:tasks_per_second] = proc{|p| p.elapsed_time}
    end
    
    def run
      @progress.start_display(5.0)
      
      # In Threads einzelne Dokumente indexieren.
      @logger.log_info "10'000 Dokumente werden indexiert und anschliessend in den Hauptindex eingegliedert."    
      threads = Config.indexer.threads.times.map do
        Thread.new do
          postings_tmps = Common::RAMCacheLRU.new(1000)
          while @progress[:tasks] < 10_000 and (doc_id = Indexer::Database.index_queue_fetch)
            Task.load(doc_id, postings_tmps).run
            @progress[:tasks] += 1
          end
          postings_tmps.remove_all
        end
      end
      
      # Warten bis alle Workerthreads fertig sind.
      threads.map{|t| t.join}
      @progress.stop
    
      # Sortieren beginnen
      @logger.log_info "Sortieren der Zwischenergebnisse gestartet."
      tempfiles = Dir[File.join(Config.paths.index_tmp, "word:*")]
      @logger.log_info "Anzahl zu sortierender Dateien: #{tempfiles.size}"
      @progress.restart
    
      tempfiles.each do |tempfile|
        word = tempfile.split(":")[1]
      
        # Überprüfen ob bereits eine gesicherte Indexdatei existiert, falls ja wird diese ans Ende des tempfile gehängt
        # und die originale gelöscht...
        destination_path = File.join(Config.paths.postings, word)
        if File.exist? destination_path
          File.open(tempfile, "a") do |file|
            file.write(File.binread(destination_path))
          end
          File.unlink destination_path
        end
      
        # Die temporäre Datei in die Zieldatei hineinsortieren und die temporäre Datei anschliessend löschen.
        destination_file = Common::PostingsFile.new(destination_path, true)
        IndexSorter.sort(Common::PostingsFile.new(tempfile, true), destination_file)
        @progress[:tasks] += 1
        File.unlink tempfile
        
        # PostingsMetadata-File generieren
        Common::PostingsMetadataFile.new(word).generate_for(destination_file)
      end
      
      @progress.stop
    
      @logger.log_info "10'000 Dokumente erfolgreich indexiert und in Hauptindex eingegliedert."
    end
  end
end


if __FILE__ == $0
  Indexer::Main.new.run()
end
