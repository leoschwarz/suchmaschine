#!/usr/bin/env ruby
require_relative '../lib/common/common.rb'
require_relative '../lib/indexer/indexer.rb'

# TODO: Eventuell wäre es auch interessant BigQueue um eine Bestätigungsfunktion zu erweitern, bzw. eine andere Warteschlange mit solcher Funktionalität
#       zu implementieren. So wäre es sichergestellt, dass einzelne Einträge am Ende nicht ohne Indexeinträge bleiben.

module Indexer
  class Main
    def initialize
      @logger = Common::Logger.new({labels: {tasks: "Aufgaben", tasks_per_second: "Aufgaben/s"}})
      @logger.progress[:tasks] = 0
      @logger.progress[:tasks_per_second] = proc do |logger|
        if logger.elapsed_time.round == 0
          "N/A"
        else
          (logger.progress[:tasks]*1.0/logger.elapsed_time).round(1)
        end
      end
      @logger.add_output($stdout, Common::Logger::INFO)
      
      # Thread, um den Fortschrittszähler kontinuierlich auszugeben, starten.
      Thread.new do
        loop do
          @logger.log_progress if @show_progress
          sleep 5
        end
      end
    end
    
    def run
      # In Threads einzelne Dokumente indexieren.
      @logger.log_info "10'000 Dokumente werden indexiert und anschliessend in den Hauptindex eingegliedert."    
      start_progress_display
      threads = Config.indexer.threads.times.map do
        Thread.new do
          while @logger.progress[:tasks] < 10_000 and (doc_id = Indexer::Database.index_queue_fetch)
            Task.load(doc_id).run
            @logger.progress[:tasks] += 1
          end
        end
      end
    
      # Warten bis alle Workerthreads fertig sind.
      threads.map{|t| t.join}
      stop_progress_display
    
      # Sortieren beginnen
      @logger.log_info "Sortieren der Zwischenergebnisse gestartet."
      tempfiles = Dir[File.join(Config.paths.index_tmp, "word:*")]
      @logger.log_info "Anzahl zu sortierender Dateien: #{tempfiles.size}"
      start_progress_display
    
      tempfiles.each do |tempfile|
        word = tempfile.split(":")[1]
      
        # Überprüfen ob bereits eine gesicherte Indexdatei existiert, falls ja wird diese ans Ende des tempfile gehängt
        # und die originale gelöscht...
        destination_path = File.join(Config.paths.index, "word:#{word}")
        if File.exist? destination_path
          File.open(tempfile, "a") do |file|
            file.write(File.binread(destination_path))
          end
          File.unlink destination_path
        end
      
        # Die temporäre Datei in die Zieldatei hineinsortieren und die temporäre Datei anschliessend löschen.
        destination_file = Common::PostingsFile.new(destination_path)
        IndexSorter.sort(Common::PostingsFile.new(tempfile), destination_file)
        @logger.progress[:tasks] += 1
        File.unlink tempfile
        
        # PostingsMetadata-File generieren
        Common::PostingsMetadataFile.new(destination_path + ".meta").generate_for(destination_file)
      end
      
      stop_progress_display
    
      @logger.log_info "10'000 Dokumente erfolgreich indexiert und in Hauptindex eingegliedert."
    end
    
    def start_progress_display
      @logger.progress[:tasks] = 0
      @logger.reset_elapsed_time
      @logger.log_progress_labels
      @show_progress = true
    end
    
    def stop_progress_display
      @show_progress = false
    end
  end
end


if __FILE__ == $0
  Indexer::Main.new.run()
end
